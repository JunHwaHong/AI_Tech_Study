# PyTorch Basic
1. PyTorch 기본
   : PyTorch의 기본과 딥러닝 프로젝트 구조에 대한 개념
2. PyTorch 구조 학습 (1)
   : PyTorch에서의 AutoGrad & Optimizer 그리고 Dataset과 DataLoader와 관련된 개념
3. PyTorch 구조 학습 (2)
   : PyTorch에서 모델을 불러오고 여러 실험을 관리하는 도구와 관련된 개념
4. PyTorch 활용
   : PyTorch에서 병렬 학습과 학습시 발생할 수 있는 여러 가지 문제점들
---
# 01. Introduction to PyTorch

### PyTorch란?
```
PyTorch는 딥러닝을 개발하는 가장 기본이 되는 framework이다.
```
### Deep Learning Framework 종류
* mxnet, CNTK, Caffe2, Tensorflow, Keras, PyTorch, theano 등등 엄청 많다!
* 현재는 Pytorch(facebook), TensorFlow(Google) 두가지가 많이 사용된다


### PyTorch vs TensorFlow
![화면 캡처 2022-01-27 133216](https://user-images.githubusercontent.com/44192730/151292407-1fefd6d4-462e-460a-9158-c36519f2ff69.png)

* PyTorch는 Dynamic Computation Graph, TensorFlow는 Define and run 형식
 
![화면 캡처 2022-01-27 133442](https://user-images.githubusercontent.com/44192730/151292623-eb797195-acfd-4722-ac5a-0510d5e7479a.png)

* g = (x + y) * z (그래프 예시)
* Define and Run : 그래프를 먼저 정의하고 실행 시점에 데이터를 feed 시켜준다
* Dynamic Computational Graph, DCG) : 실행을 하면서 그래프를 생성하는 방식
---
# 02. PyTorch Basics
* Tensor : list, np.ndarray를 사용하여 만들 수 있다, Device를 사용하여 GPU에서 사용도 가능
* 행렬 곱셈을 dot이 아닌 mm을 사용한다.

* AutoGrad : 자동 미분 지원 -> backward 함수 사용
---
# 03. PyTorch 프로젝트 구조 이해
* DL 프로젝트도 배포를 위해 개발 용이성과 유지보수를 고려해야 한다.
* 실행, 데이터, 모델, 설정, 로깅, 지표, 유틸리티등 다양한 모듈을 분리하여 프로젝트 템플릿화
* 실행 : train,py, test.py
* 설정 : config file
* data : dataloader
* model : model.py, metric.py, loss.py
* storage : log, model status
* trainer
* logger
* utils
---
# 04. AutoGrad & Optimizer
#### torch.nn.Module
* 딥러닝을 구성하는 layer의 base class
* input, output, forward, backward를 정의 해주어야 한다

#### nn.Parameter
* Tensor 객체의 상속 객체
* nn.Module내에서 autograd의 대상이 된다

#### Backward
* Layer에 있는 parameter들의 미분을 수행한다
* forward의 결과와 실제값의 차이에 대해 미분을 수행한다
* 해당 값으로 Parameter 업데이트

# Dataset, Dataloader
* 데이터를 넣어주는 기본이 되는 구조
#### Dataset : 데이터 입력형태를 정의하는 클래스
* __init__()
* __len__()
* __getitem__() : 데이터를 불러올때 어떻게 반환해줄지 정의

#### Transforms : 데이터 전처리

#### DataLoader : 데이터의 batch를 생성해주는 클래스
* sampler : 데이터를 어떻게 뽑을지 인덱스를 정해주는 기법
* collate_fn [https://hulk89.github.io/pytorch/2019/09/30/pytorch_dataset/]

---
# 06. 모델 불러오기

#### 모델을 학습하고 형태, 중간 과정을 저장
#### checkpoint
* 학습의 중간 결과를 저장하여 최선의 결과를 선택
* loss, metric값을 지속적으로 확인 저장

### Transfer learing
* 다른 데이터 셋으로 만든 모델을 현재 데이터에 적용
* backbone architecture가 잘 학습된 모델에서 일부분만 변경하여 학습을 수행

#### Freezing
* pretrain model을 활용 시 모델의 일부분을 frozen시킴
---
# Monitoring Tool
#### Tensorboard vs wandb
* wandb를 더 연습해보자

# Hyperparameter tuning
* 모델 스스로 학습하지 않는 값, 사람이 지정
* 조금의 0.01의 성능이라도 올려야 하는 경우에 도전할 만

### Ray
* multi-node multi processing 지원 모듈
* ML/DL 병렬처리를 도와주는 모듈

---

### 참고 자료
#### 딥러닝 프레임워크
* https://data-newbie.tistory.com/425
* https://bit.ly/3j9Vpdg

#### Study more
* https://wikidocs.net/book/2788

#### 프로젝트 구조
* https://github.com/victoresque/pytorch-template

